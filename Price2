import os
import json
import shutil

# 경로 설정 (로컬 파일 시스템 경로로 수정)
drive_path = r'C:\Users\mousy\TermProjectTest\Price'  # 필요한 경로로 수정하세요
data_path = os.path.join(drive_path)

# JSON 파일 경로 목록
json_files = [
    'augmentation_data_info.json.part0',
    'textinthewild_data_info.json.part0',
    'printed_data_info.json.part0',
    'handwriting_data_info_clean.json.part0'
]

# 디렉토리 생성 및 LMDB 데이터셋 생성 함수
def create_lmdb_dataset(file_name):
    ground_truth_path = os.path.join(drive_path, f'ground-truth-{file_name.split(".")[0]}')
    file_path = os.path.join(data_path, file_name)
    gt_file_path = os.path.join(ground_truth_path, 'gt.txt')

    # 디렉토리 생성
    if not os.path.exists(ground_truth_path):
        os.makedirs(ground_truth_path)

    # JSON 데이터 로드 및 gt.txt 파일 생성
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            json_data = json.load(file)
    except FileNotFoundError as e:
        print(f"Error: {e}")
        print("Please check if the JSON file path is correct.")
        return

    with open(gt_file_path, 'w', encoding='utf-8') as gt_file:
        for data in json_data['annotations']:
            img_name = f"{data['id']}.png"
            img_src = os.path.join(data_path, img_name)
            img_dst = os.path.join(ground_truth_path, img_name)
            if os.path.exists(img_src):
                shutil.copy(img_src, img_dst)
                gt_file.write(f"ground-truth-{file_name.split('.')[0]}/{img_name}\t{data['text']}\n")

    # LMDB 데이터셋 생성
    !python3 create_lmdb_dataset.py --gtFile "{gt_file_path}" --inputPath "{ground_truth_path}" --outputPath "{ground_truth_path}/lmdb_dataset"

# deep-text-recognition-benchmark 리포지토리 클론
!git clone https://github.com/clovaai/deep-text-recognition-benchmark.git
%cd deep-text-recognition-benchmark

# fire 패키지 설치
!pip install fire

# Torch 최신 버전 설치
!pip install --upgrade torch

# dataset.py 파일 수정
dataset_file_path = r"C:\Users\mousy\deep-text-recognition-benchmark\dataset.py"
with open(dataset_file_path, 'r') as file:
    data = file.read()

data = data.replace('from torch._utils import _accumulate', 'from itertools import accumulate as _accumulate')

with open(dataset_file_path, 'w') as file:
    file.write(data)

# 각 JSON 파일에 대해 LMDB 데이터셋 생성
for json_file in json_files:
    create_lmdb_dataset(json_file)
