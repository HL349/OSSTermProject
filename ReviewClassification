# 필요한 라이브러리 임포트
import pandas as pd
import torch
from transformers import BertTokenizer, BertForSequenceClassification
from nltk.tokenize import sent_tokenize
from nltk.corpus import stopwords
from nltk import download
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

# NLTK 데이터 다운로드
download('punkt')
download('stopwords')

# BERT 모델과 토크나이저 로드
model_name = 'bert-base-multilingual-cased'
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertForSequenceClassification.from_pretrained(model_name)

# 크롬 드라이버 설정
service = Service(r"C:\Users\mousy\TermProject\chromedriver.exe")
driver = webdriver.Chrome(service=service)

# 네이버 지도 특정 URL로 이동
driver.get("https://m.place.naver.com/place/13304144/review/visitor?entry=plt")

# 페이지 로딩 대기
time.sleep(5)

# 페이지 소스 가져오기
page_source = driver.page_source

# BeautifulSoup을 사용하여 리뷰 데이터 추출
soup = BeautifulSoup(page_source, 'html.parser')
reviews = soup.find_all('span', {'class': 'WoYOw'})  # 리뷰 텍스트가 있는 실제 태그와 클래스 이름으로 변경 필요

# 리뷰 텍스트 추출 및 빈 문자열 필터링
review_texts = [review.get_text().strip() for review in reviews if review.get_text().strip()]

# 크롬 드라이버 종료
driver.quit()

# 리뷰 텍스트가 비어 있지 않은지 확인
if not review_texts:
    raise ValueError("수집된 리뷰가 없습니다. 다시 확인하세요.")

# 리뷰 데이터를 판다스 데이터프레임으로 변환
df = pd.DataFrame(review_texts, columns=['review'])

# 리뷰 데이터를 토큰화하고 텐서로 변환
tokens = tokenizer(df['review'].tolist(), return_tensors='pt', padding=True, truncation=True, max_length=512)

# 모델로 확률 계산
outputs = model(**tokens)
probs = torch.nn.functional.softmax(outputs.logits, dim=-1)

# 긍정/부정 분류
positive_reviews = []
negative_reviews = []

for i, prob in enumerate(probs):
    if prob[1] > prob[0]:  # 긍정 확률이 더 높으면
        positive_reviews.append(df['review'][i])
    else:  # 부정 확률이 더 높으면
        negative_reviews.append(df['review'][i])

# NLTK를 사용하여 키워드 추출
stop_words = set(stopwords.words('korean'))

def get_keywords(reviews):
    all_words = ' '.join(reviews)
    words = [word for word in all_words.split() if word not in stop_words]
    freq_dist = nltk.FreqDist(words)
    return freq_dist.most_common(10)

positive_keywords = get_keywords(positive_reviews)
negative_keywords = get_keywords(negative_reviews)

print("긍정 리뷰 키워드:", positive_keywords)
print("부정 리뷰 키워드:", negative_keywords)
